{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e78215b",
   "metadata": {},
   "source": [
    "# Pytorch Tutorial: Card Classifier\n",
    "\n",
    "adapted from Rob Mullay's [PyTorch tutorial](https://www.youtube.com/watch?v=tHL5STNJKag).\n",
    "\n",
    "Before we start we import all the libraries and setup basic functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0516ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import timm\n",
    "\n",
    "import matplotlib.pyplot as plt # For data viz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print('System Version:', sys.version)\n",
    "print('PyTorch version', torch.__version__)\n",
    "print('Torchvision version', torchvision.__version__)\n",
    "print('Numpy version', np.__version__)\n",
    "print('Pandas version', pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700af0d0",
   "metadata": {},
   "source": [
    "## Step 1: PyTorch Dataset and Dataloader\n",
    "\n",
    "Pytorch's `Dataset` is very flexible. It can be used to load any kind of data, including images, text, etc.\n",
    "Then you can wrap it with a `DataLoader`, which will automatically shuffle your data and batch it for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938343c9",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd08bf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlayingCardDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data = ImageFolder(data_dir, transform=transform)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "    @property\n",
    "    def classes(self):\n",
    "        return self.data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9db87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data:\n",
    "dataset = PlayingCardDataset(data_dir='./dataset/train')\n",
    "\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcc8426",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = dataset[2000]\n",
    "print(label)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3ab48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a dictionary associating target values with folder names\n",
    "data_dir = './dataset/train'\n",
    "target_to_class = {v: k for k, v in ImageFolder(data_dir).class_to_idx.items()}\n",
    "\n",
    "for key, value in target_to_class.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78004a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the dataset images to 128x128 pixels (each pixel is a RGB value)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "data_dir = './dataset/train'\n",
    "dataset = PlayingCardDataset(data_dir, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2a900b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = dataset[100]\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63950c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over dataset\n",
    "for image, label in dataset:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbe3222",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838a3f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926478e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over dataloader\n",
    "for images, labels in dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9f5871",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6290feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b43f0d",
   "metadata": {},
   "source": [
    "## Step 2: Pytorch Model\n",
    "\n",
    "Pytorch datasets have a structured way of organizing your data, pytorch models follow a similar paradigm.\n",
    "\n",
    "- We could create the model from scratch defining each layer.\n",
    "- However for tasks like image classification, many of the state of the art architectures are readily available and we can import them from packages like timm.\n",
    "- Understanding the pytorch model is all about understanding the shape the data is at each layer, and the main one we need to modify for a task is the final layer. Here we have 53 targets, so we will modify the last layer for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb91501",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCardClassifer(nn.Module):\n",
    "    def __init__(self, num_classes=53):\n",
    "        super(SimpleCardClassifer, self).__init__()\n",
    "        # Where we define all the parts of the model\n",
    "        self.base_model = timm.create_model('efficientnet_b0', pretrained=True) # Will output a feature size of 1280\n",
    "        self.features = nn.Sequential(*list(self.base_model.children())[:-1]) # Remove the last layer of the base model\n",
    "        enet_out_size = 1280 # We will resize the output size of 1280 to 53\n",
    "        self.classifier = nn.Sequential(nn.Flatten(), nn.Linear(enet_out_size, num_classes)) # Make a classifier\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Connect these parts and return the output\n",
    "        x = self.features(x)\n",
    "        output = self.classifier(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363e9a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCardClassifer(num_classes=53)\n",
    "print(str(model)[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f79d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_out = model(images)\n",
    "print(example_out)\n",
    "example_out.shape # [batch_size, num_classes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4626c9b3",
   "metadata": {},
   "source": [
    "## Step 3: The training loop\n",
    "\n",
    "- Now that we understand the general paradigm of pytorch datasets and models, we need to create the process of training this model.\n",
    "- Some things to consider: We want to validate our model on data it has not been trained on, so usually we split our data into a train and validate datasets. This is easy because we can just create two datasets using our existing class.\n",
    "    - Terms:\n",
    "        - `epoch`: One run through the entire training dataset.\n",
    "        - `step`: One batch of data as defined in our dataloader\n",
    "- This loop is one you will become familiar with when training models, you load in data to the model in batches - then calculate the loss and perform backpropagation. There are packages that package this for you, but it's good to have at least written it once to understand how it works.\n",
    "- Two things to select:\n",
    "    - optimizer, `adam` is the best place to start for most tasks.\n",
    "    - loss function: What the model will optimize for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076fed32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40089f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion(example_out, labels)\n",
    "print(example_out.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cdad84",
   "metadata": {},
   "source": [
    "### Setup Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3a7dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_folder = './dataset/train/'\n",
    "valid_folder = './dataset/valid/'\n",
    "test_folder = './dataset/test/'\n",
    "\n",
    "train_dataset = PlayingCardDataset(train_folder, transform=transform)\n",
    "val_dataset = PlayingCardDataset(valid_folder, transform=transform)\n",
    "test_dataset = PlayingCardDataset(test_folder, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3857b05",
   "metadata": {},
   "source": [
    "### Simple Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03eff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple training loop\n",
    "num_epochs = 5\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "# Use GPU if available else use the CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = SimpleCardClassifer(num_classes=53)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader, desc='Training loop'):\n",
    "        # Move inputs and labels to the device\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc='Validation loop'):\n",
    "            # Move inputs and labels to the device\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "         \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "    val_loss = running_loss / len(val_loader.dataset)\n",
    "    val_losses.append(val_loss)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train loss: {train_loss}, Validation loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ead7b9e",
   "metadata": {},
   "source": [
    "### Visualize Losses\n",
    "\n",
    "We can plot our training and validation loss through this training, usually we do this at the end of each epoch. We see that our accuracy on the validation dataset is `x`! There are a LOT more things to learn about that can drastically improve how to train a model which I will cover in future videos, but this should give you a good start!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f490fa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(val_losses, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss over epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf389af",
   "metadata": {},
   "source": [
    "### Evaluating the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a978c7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load and preprocess the image\n",
    "def preprocess_image(image_path, transform):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    return image, transform(image).unsqueeze(0)\n",
    "\n",
    "# Predict using the model\n",
    "def predict(model, image_tensor, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        image_tensor = image_tensor.to(device)\n",
    "        outputs = model(image_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "    return probabilities.cpu().numpy().flatten()\n",
    "\n",
    "# Visualization\n",
    "def visualize_predictions(original_image, probabilities, class_names):\n",
    "    fig, axarr = plt.subplots(1, 2, figsize=(14, 7))\n",
    "    \n",
    "    # Display image\n",
    "    axarr[0].imshow(original_image)\n",
    "    axarr[0].axis(\"off\")\n",
    "    \n",
    "    # Display predictions\n",
    "    axarr[1].barh(class_names, probabilities)\n",
    "    axarr[1].set_xlabel(\"Probability\")\n",
    "    axarr[1].set_title(\"Class Predictions\")\n",
    "    axarr[1].set_xlim(0, 1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "test_image = \"./dataset/test/five of diamonds/2.jpg\"\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "original_image, image_tensor = preprocess_image(test_image, transform)\n",
    "probabilities = predict(model, image_tensor, device)\n",
    "\n",
    "# Assuming dataset.classes gives the class names\n",
    "class_names = dataset.classes \n",
    "visualize_predictions(original_image, probabilities, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f43cf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "test_images = glob('./dataset/test/*/*')\n",
    "test_examples = np.random.choice(test_images, 10)\n",
    "\n",
    "for example in test_examples:\n",
    "    original_image, image_tensor = preprocess_image(example, transform)\n",
    "    probabilities = predict(model, image_tensor, device)\n",
    "\n",
    "    # Assuming dataset.classes gives the class names\n",
    "    class_names = dataset.classes \n",
    "    visualize_predictions(original_image, probabilities, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28294d24",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fbcad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy of the model on the test dataset\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:  # or val_loader if test_loader doesn't exist\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy of the model on the test set: {accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zhaw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
